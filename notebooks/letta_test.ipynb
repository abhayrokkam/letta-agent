{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm  -f ~/.letta/sqlite.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import letta\n",
    "from letta.schemas.memory import ChatMemory\n",
    "\n",
    "import chromadb\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import os\n",
    "import sys\n",
    "super_directory = os.path.abspath('..')\n",
    "sys.path.append(super_directory)\n",
    "\n",
    "from modules.prompts import sanjay_persona, system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the letta_client and setting default LLM and Embedding Model\n",
    "letta_client = letta.create_client()\n",
    "\n",
    "letta_client.set_default_llm_config(letta.LLMConfig.default_config(\"gpt-4o-mini\")) \n",
    "letta_client.set_default_embedding_config(letta.EmbeddingConfig.default_config(\"text-embedding-ada-002\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting agent name\n",
    "agent_name = 'dr_sanjay_sarma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the vector_db with Sanjay Sarma's information\n",
    "chroma_client = chromadb.PersistentClient(path='../chromadb')\n",
    "sanjay_collection = chroma_client.get_collection(name='sanjay_sarma')\n",
    "\n",
    "vdb_embed_model = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "\n",
    "vectordb = Chroma(\n",
    "    collection_name='sanjay_sarma',\n",
    "    embedding_function=vdb_embed_model,\n",
    "    persist_directory=\"../chromadb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function as tool\n",
    "def get_sanjay_information(query: str):\n",
    "    \"\"\"\n",
    "    Retrieves relevant information related to a query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string for which information is being retrieved.\n",
    "\n",
    "    Returns:\n",
    "        str: The concatenated content of the relevant search results based on the query.\n",
    "    \"\"\"\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from langchain.vectorstores import Chroma\n",
    "    \n",
    "    vdb_embed_model = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "    vectordb = Chroma(\n",
    "        collection_name='sanjay_sarma',\n",
    "        embedding_function=vdb_embed_model,\n",
    "        persist_directory=\"../chromadb\")\n",
    "    \n",
    "    text = \"\"\n",
    "    results = vectordb.similarity_search(query, k=5)\n",
    "    for result in results:\n",
    "        text += result.page_content\n",
    "    return text\n",
    "\n",
    "get_info_tool = letta_client.create_tool(get_sanjay_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sanjay agent\n",
    "agent_state = letta_client.create_agent(\n",
    "    name=agent_name,\n",
    "    tool_ids=[get_info_tool.id],\n",
    "    memory=ChatMemory(\n",
    "        human=\"\",\n",
    "        persona=sanjay_persona\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created agent with name {agent_state.name} and unique ID {agent_state.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the system prompt\n",
    "agent_state.system = system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting and printing response\n",
    "user_message = \"which story are you referring to that inspired your education\"\n",
    "\n",
    "response = letta_client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message=user_message, \n",
    "    role=\"user\" \n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# for message in response.dict()['messages']:\n",
    "#     if message.get('message_type') == 'tool_call_message' and message.get('tool_call', {}).get('name') == 'send_message':\n",
    "#         message_reply = message['tool_call']['arguments']\n",
    "        \n",
    "#         print(json.loads(message_reply)['message'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".chat-memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
